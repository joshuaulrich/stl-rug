By: Jenine Harris

Science is currently facing a "reproducibility crisis" where researchers find it difficult or impossible to reproduce study results. This presentation has three goals related to reproducible: (1) describe current practice among social scientists, (2) identify challenges and opportunities, and (3) teach practical strategies for analysts to improve reproducibility.

We surveyed social scientists who recently conducted statistical analyses for a report or manuscript. A total of 247 of 278 screened eligible and 209 answered every applicable question. Most participants reported using promising coding and file management practices. Over half of researchers reported that, if they suddenly left their position, it would be easy for others to find their data (67%) and code (57%). Code sharing was uncommon with just 9% reporting sharing code from a recent publication and 20% of those surveyed reported ever having shared code publicly. Participants identified barriers including lack of training (n=108), data privacy issues (n=105), and journals and funders not requiring reproducibility. Few participants identified fear of errors being discovered (n=26) or a lack of workplace incentives (n=32) as barriers.

Improving research reproducibility is a big task. We suggest three strategies:
1. use existing guidelines to write code
2. publicly share statistical code—or adequate details about methodology in the main text or supplemental materials—for each publication or report
3. publicly share original, de-identified, or simulated data whenever possible

You can find all of Jenine's presentation materials on [her GitHub repo](https://github.com/jenineharris/stl_rug_08072019).
